behaviors:
  OrbitPilotAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      beta: 0.001
      epsilon: 0.2
      lambd: 0.99
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 1000
    summary_freq: 12000
  SphereLandingAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      beta: 0.001
      epsilon: 0.2
      lambd: 0.99
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 1000
    summary_freq: 12000
  SpherePilotAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 128
      buffer_size: 12000
      learning_rate: 0.0003
      beta: 0.001
      epsilon: 0.2
      lambd: 0.99
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 256
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 1000
    summary_freq: 10000
  PlaneLandingAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      beta: 0.001
      epsilon: 0.2
      lambd: 0.99
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 1000
    summary_freq: 12000
  PlanePilotAgent:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      beta: 0.001
      epsilon: 0.2
      lambd: 0.99
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 1000
    summary_freq: 12000
  Test:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      beta: 0.001
      epsilon: 0.2
      lambd: 0.99
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 3
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000
    time_horizon: 1000
    summary_freq: 12000
environment_parameters:
  landing_randomization:
    curriculum:
      - name: Lesson0
        completion_criteria:
          measure: reward
          behavior: SphereLandingAgent
          signal_smoothing: true
          min_lesson_length: 20
          threshold: 3
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 0.0
            max_value: 0.0
      - name: Lesson1
        completion_criteria:
          measure: reward
          behavior: SphereLandingAgent
          signal_smoothing: true
          min_lesson_length: 100
          threshold: 2.9
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 0.0
            max_value: 1.0
      - name: Lesson2
        completion_criteria:
          measure: reward
          behavior: SphereLandingAgent
          signal_smoothing: true
          min_lesson_length: 20
          threshold: 2.8
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 0.0
            max_value: 2.0
      - name: Lesson3
        completion_criteria:
          measure: reward
          behavior: SphereLandingAgent
          signal_smoothing: true
          min_lesson_length: 200
          threshold: 2.3
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 1.0
            max_value: 3.0
      - name: Lesson4
        completion_criteria:
          measure: reward
          behavior: SphereLandingAgent
          signal_smoothing: true
          min_lesson_length: 300
          threshold: 2.6
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 1.0
            max_value: 4.0
      - name: Lesson5
        completion_criteria:
          measure: reward
          behavior: SphereLandingAgent
          signal_smoothing: true
          min_lesson_length: 300
          threshold: 2.4
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 2.0
            max_value: 5.0
      - name: MyLastLesson
        value:
          sampler_type: uniform
          sampler_parameters:
            min_value: 2.0
            max_value: 5.0